{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from attention import AttentionLayer\n",
    "from contraction_mapping import *\n",
    "\n",
    "\n",
    "import numpy as np  \n",
    "import pandas as pd \n",
    "import re           \n",
    "from bs4 import BeautifulSoup \n",
    "from keras.preprocessing.text import Tokenizer \n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from nltk.corpus import stopwords   \n",
    "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Concatenate, TimeDistributed, Bidirectional\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import warnings\n",
    "pd.set_option(\"display.max_colwidth\", 200)\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('training_dataset/train.ast.src', 'r')\n",
    "code_data = []\n",
    "for i in range(5000):\n",
    "    input_data = str(f.readline())\n",
    "    code_data.append(input_data)\n",
    "f.close()\n",
    "\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "stop_words.remove('if')\n",
    "stop_words.remove('for')\n",
    "stop_words.remove('this')\n",
    "\n",
    "\n",
    "f = open('training_dataset/train.txt.tgt', 'r')\n",
    "summary_data = []\n",
    "for i in range(5000):\n",
    "    input_data = str(f.readline())\n",
    "    summary_data.append(input_data)\n",
    "f.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summary_cleaner(text):\n",
    "    newString = re.sub('\"','', text)\n",
    "    newString = ' '.join([contraction_mapping[t] if t in contraction_mapping else t for t in newString.split(\" \")])    \n",
    "    newString = re.sub(r\"'s\\b\",\"\",newString)\n",
    "    newString = re.sub(\"[^a-zA-Z]\", \" \", newString)\n",
    "    newString = newString.lower()\n",
    "    tokens=newString.split()\n",
    "    newString=''\n",
    "    for i in tokens:\n",
    "        if len(i)>1:                                 \n",
    "            newString=newString+i+' '  \n",
    "    return newString"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_summary = []\n",
    "for t in summary_data:\n",
    "    cleaned_summary.append(summary_cleaner(t))\n",
    "\n",
    "for i in range(len(cleaned_summary)):\n",
    "    cleaned_summary[i] = '_START_ '+ cleaned_summary[i] + ' _END_'\n",
    "\n",
    "# print(cleaned_summary[23])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "622\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "text_word_count = []\n",
    "summary_word_count = []\n",
    "\n",
    "print(len(code_data[1000]))\n",
    "\n",
    "for i in code_data:\n",
    "    text_word_count.append(len(i.split()))\n",
    "\n",
    "for i in cleaned_summary:\n",
    "    summary_word_count.append(len(i.split()))\n",
    "\n",
    "length_df = pd.DataFrame({'text':text_word_count, 'summary':summary_word_count})\n",
    "length_df.to_csv('length_data.csv')\n",
    "length_df.hist(bins = 30)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len_text = 300\n",
    "max_len_summary = 40\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_tr,x_val,y_tr,y_val=train_test_split(code_data, cleaned_summary, test_size=0.1, random_state=0, shuffle=True) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_tokenizer = Tokenizer()\n",
    "x_tokenizer.fit_on_texts(list(x_tr))\n",
    "\n",
    "#convert text sequences into integer sequences\n",
    "x_tr    =   x_tokenizer.texts_to_sequences(x_tr) \n",
    "x_val   =   x_tokenizer.texts_to_sequences(x_val)\n",
    "\n",
    "#padding zero upto maximum length\n",
    "x_tr    =   pad_sequences(x_tr,  maxlen=max_len_text, padding='post') \n",
    "x_val   =   pad_sequences(x_val, maxlen=max_len_text, padding='post')\n",
    "\n",
    "x_voc_size   =  len(x_tokenizer.word_index) +1\n",
    "\n",
    "y_tokenizer = Tokenizer()\n",
    "y_tokenizer.fit_on_texts(list(y_tr))\n",
    "\n",
    "#convert summary sequences into integer sequences\n",
    "y_tr    =   y_tokenizer.texts_to_sequences(y_tr) \n",
    "y_val   =   y_tokenizer.texts_to_sequences(y_val) \n",
    "\n",
    "#padding zero upto maximum length\n",
    "y_tr    =   pad_sequences(y_tr, maxlen=max_len_summary, padding='post')\n",
    "y_val   =   pad_sequences(y_val, maxlen=max_len_summary, padding='post')\n",
    "\n",
    "y_voc_size  =   len(y_tokenizer.word_index) +1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K \n",
    "K.clear_session() \n",
    "latent_dim = 20\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoder attempt with 3 LSTM layers\n",
    "encoder_inputs = Input(shape=(max_len_text,)) \n",
    "enc_emb = Embedding(x_voc_size, latent_dim,trainable=True)(encoder_inputs) \n",
    "\n",
    "#LSTM 1 \n",
    "encoder_lstm1 = LSTM(latent_dim,return_sequences=True,return_state=True) \n",
    "encoder_output1, state_h1, state_c1 = encoder_lstm1(enc_emb) \n",
    "\n",
    "#LSTM 2 \n",
    "encoder_lstm2 = LSTM(latent_dim,return_sequences=True,return_state=True) \n",
    "encoder_output2, state_h2, state_c2 = encoder_lstm2(encoder_output1) \n",
    "\n",
    "#LSTM 3 \n",
    "encoder_lstm3=LSTM(latent_dim, return_state=True, return_sequences=True) \n",
    "encoder_outputs, state_h, state_c= encoder_lstm3(encoder_output2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 300)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 300, 20)      353560      input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     [(None, 300, 20), (N 3280        embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   [(None, 300, 20), (N 3280        lstm[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, None, 20)     107460      input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   [(None, 300, 20), (N 3280        lstm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lstm_3 (LSTM)                   [(None, None, 20), ( 3280        embedding_1[0][0]                \n",
      "                                                                 lstm_2[0][1]                     \n",
      "                                                                 lstm_2[0][2]                     \n",
      "__________________________________________________________________________________________________\n",
      "attention_layer (AttentionLayer ((None, None, 20), ( 820         lstm_2[0][0]                     \n",
      "                                                                 lstm_3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concat_layer (Concatenate)      (None, None, 40)     0           lstm_3[0][0]                     \n",
      "                                                                 attention_layer[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed (TimeDistribut (None, None, 5373)   220293      concat_layer[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 695,253\n",
      "Trainable params: 695,253\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Decoder\n",
    "decoder_inputs = Input(shape=(None,)) \n",
    "dec_emb_layer = Embedding(y_voc_size, latent_dim,trainable=True) \n",
    "dec_emb = dec_emb_layer(decoder_inputs) \n",
    "\n",
    "#LSTM using encoder_states as initial state\n",
    "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True) \n",
    "decoder_outputs,decoder_fwd_state, decoder_back_state = decoder_lstm(dec_emb,initial_state=[state_h, state_c]) \n",
    "\n",
    "#Attention Layer\n",
    "attn_layer = AttentionLayer(name='attention_layer') \n",
    "attn_out, attn_states = attn_layer([encoder_outputs, decoder_outputs]) \n",
    "\n",
    "# Concat attention output and decoder LSTM output \n",
    "decoder_concat_input = Concatenate(axis=-1, name='concat_layer')([decoder_outputs, attn_out])\n",
    "\n",
    "#Dense layer\n",
    "decoder_dense = TimeDistributed(Dense(y_voc_size, activation='softmax')) \n",
    "decoder_outputs = decoder_dense(decoder_concat_input) \n",
    "\n",
    "# Define the model\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs) \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert the index to word for target and source vocabulary\n",
    "reverse_target_word_index=y_tokenizer.index_word \n",
    "reverse_source_word_index=x_tokenizer.index_word \n",
    "target_word_index=y_tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_model = Model(inputs=encoder_inputs,outputs=[encoder_outputs, state_h, state_c])\n",
    "\n",
    "# decoder inference\n",
    "# Below tensors will hold the states of the previous time step\n",
    "decoder_state_input_h = Input(shape=(latent_dim,))\n",
    "decoder_state_input_c = Input(shape=(latent_dim,))\n",
    "decoder_hidden_state_input = Input(shape=(max_len_text,latent_dim))\n",
    "\n",
    "# Get the embeddings of the decoder sequence\n",
    "dec_emb2= dec_emb_layer(decoder_inputs)\n",
    "\n",
    "# To predict the next word in the sequence, set the initial states to the states from the previous time step\n",
    "decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=[decoder_state_input_h, decoder_state_input_c])\n",
    "\n",
    "#attention inference\n",
    "attn_out_inf, attn_states_inf = attn_layer([decoder_hidden_state_input, decoder_outputs2])\n",
    "decoder_inf_concat = Concatenate(axis=-1, name='concat')([decoder_outputs2, attn_out_inf])\n",
    "\n",
    "# A dense softmax layer to generate prob dist. over the target vocabulary\n",
    "decoder_outputs2 = decoder_dense(decoder_inf_concat)\n",
    "\n",
    "# Final decoder model\n",
    "decoder_model = Model(\n",
    "[decoder_inputs] + [decoder_hidden_state_input,decoder_state_input_h, decoder_state_input_c],\n",
    "[decoder_outputs2] + [state_h2, state_c2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq):\n",
    "    # Encode the input as state vectors.\n",
    "    e_out, e_h, e_c = encoder_model.predict(input_seq)\n",
    "\n",
    "    # Generate empty target sequence of length 1.\n",
    "    target_seq = np.zeros((1,1))\n",
    "\n",
    "    # Chose the 'start' word as the first word of the target sequence\n",
    "    target_seq[0, 0] = target_word_index['start']\n",
    "\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    while not stop_condition:\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + [e_out, e_h, e_c])\n",
    "\n",
    "        # Sample a token\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_token = reverse_target_word_index[sampled_token_index]\n",
    "\n",
    "        if(sampled_token!='end'):\n",
    "            decoded_sentence += ' '+sampled_token\n",
    "\n",
    "        # Exit condition: either hit max length or find stop word.\n",
    "        if (sampled_token == 'end' or len(decoded_sentence.split()) >= (max_len_summary-1)):\n",
    "            stop_condition = True\n",
    "\n",
    "        # Update the target sequence (of length 1).\n",
    "        target_seq = np.zeros((1,1))\n",
    "        target_seq[0, 0] = sampled_token_index\n",
    "\n",
    "        # Update internal states\n",
    "        e_h, e_c = h, c\n",
    "\n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seq2summary(input_seq):\n",
    "    newString=''\n",
    "    for i in input_seq:\n",
    "      if((i!=0 and i!=target_word_index['start']) and i!=target_word_index['end']):\n",
    "        newString=newString+reverse_target_word_index[i]+' '\n",
    "    return newString\n",
    "\n",
    "def seq2text(input_seq):\n",
    "    newString=''\n",
    "    for i in input_seq:\n",
    "      if(i!=0):\n",
    "        newString=newString+reverse_source_word_index[i]+' '\n",
    "    return newString"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review: module functiondef is arguments if boolop or compare attribute user agent name request is name none compare attribute browser attribute user agent name request noteq str compare attribute version attribute user agent name request is name none return name false assign name version call name tuple call name map name int call attribute split attribute version attribute user agent name request str return compare tuple num num lte lt name version tuple num num \n",
      "Original summary: returns true if and only if the user agent of the client making the request indicates that it is microsoft internet or \n",
      "Predicted summary:  stringify stringify reduces statsd third safe safe properly blog scrolled positions with cdouble hiearchy stemmers cdouble vcpus subscribes querys largest evasion inner vms sends annotation stringify stringify sklearn layer book workflows workflows unpickling blog subdirectories grids grids grids grids\n",
      "\n",
      "\n",
      "Review: module functiondef get disk arguments name hardware devices param name uuid param if compare attribute name attribute class name hardware devices eq str arrayofvirtualdevice assign name hardware devices attribute virtualdevice name hardware devices for name device name hardware devices if boolop and compare attribute name attribute class name device eq str virtualdisk compare attribute name attribute class attribute backing name device eq str compare attribute attribute backing name device eq name uuid return name device \n",
      "Original summary: gets the disk key \n",
      "Predicted summary:  stringify stringify reduces statsd unstable rhel instances approach response collected wrapper collected observer capped rotate rotate subscribes authenticated machinery authenticated machinery unpickles ways machinery ways pages pages processors joining back third safe safe escapes previously floor truncation response raising\n",
      "\n",
      "\n",
      "Review: module functiondef arguments name pattern param name repl param name string param name count param name flags param num num return call attribute call name compile name pattern name flags name repl name string name count \n",
      "Original summary: return tuple containing \n",
      "Predicted summary:  stringify stringify reduces statsd unstable rhel rhel instances jacobian rhel response subdirectories scrolled vserver execution dkl mises metric excel tessellates vincent cmyk unavailable successive strategy successive strategy invalidates invalidates invalidates leave blanks affiliations pythonpath disk eqns minimised navigation environment\n",
      "\n",
      "\n",
      "Review: module functiondef human resource arguments return call attribute hrm human resource controller name s3db \n",
      "Original summary: controller staff used for summary view \n",
      "Predicted summary:  stringify stringify reduces statsd unstable rhel rhel instances jacobian rhel response subdirectories scrolled vserver execution dkl mises metric excel tessellates vincent cmyk unavailable successive successive unescape generic invalidates invalidates leave blanks workers housing housing recon housing housing detach recon\n",
      "\n",
      "\n",
      "Review: module functiondef fake spawn arguments assign name greenlets list functiondef inner fake spawn arguments a name func param assign name gt call attribute spawn name greenthread name func name a name kw expr call attribute append name greenlets name gt return name gt assign attribute spawn name object server name inner fake spawn with call attribute patch name mock str swift obj server spawn name inner fake spawn tryfinally expr yield for name gt name greenlets expr call attribute wait name gt name contextmanager \n",
      "Original summary: spawn and the result so we can wait on it \n",
      "Predicted summary:  stringify stringify reduces statsd unstable rhel instances approach response collected wrapper collected observer rotate rotate subscribes hiearchy machinery machinery unpickles ways ways ordering metric invalidates import import standalone white vserver method eqns introduce removed unescape gid invalidates invalidates leave\n",
      "\n",
      "\n",
      "Review: module functiondef build upgrade request arguments name web socket url param name extra headers param name web socket version param name origin param name none name default protocol version name none assign name request headers call name headers assign subscript name request headers index str sec websocket key call name gen sec key for tuple name key name value call attribute items name websocket upgrade headers assign subscript name request headers index name key name value if compare name extra headers isnot name none for tuple name key name value name extra headers assign subscript name request headers index name key name value assign subscript name request headers index str sec websocket version call name str name web socket version if compare name origin isnot name none assign subscript name request headers index str origin name origin assign name scheme ifexp compare str in name web socket url str https str http assign name args tuple name scheme call attribute get domain name web socket url assign subscript name request headers index str origin binop str s s mod name args assign name forged url call attribute replace attribute url string name web socket url str str https num assign name forged url call attribute replace name forged url str str http num assign name forged url call name url name forged url assign name upgrade request call name fuzzablerequest name forged url str get keyword headers name request headers return name upgrade request \n",
      "Original summary: create get request with the required http headers to upgrade to web sockets \n",
      "Predicted summary:  stringify stringify stdout specification stdout validated validated photo modifier then utf lag plotly terms bags modifier hiearchy zoom backslashes grayscale remote maskedarray bridge small small scargle small scargle visualization box good properties visualization box strict distro sampleproject distro snowball\n",
      "\n",
      "\n",
      "Review: module functiondef get location arguments name vm param name none return call attribute get name opts str location call attribute get cloud config value name config str location boolop or name vm call name get configured provider name opts keyword default name default location keyword search global name false \n",
      "Original summary: return the data center to use \n",
      "Predicted summary:  stringify stringify reduces statsd unstable rhel rhel instances scrolled leaks netrc rhel rhel instances rhel instances lists reduces response rewrite zoom takes subdirectories nbsvm options vmware preprocessing objects extracted extracted hiearchy boundaries labels laplace guest guest pressure pda blog\n",
      "\n",
      "\n",
      "Review: module functiondef arguments name filename param name param assign name outfile call name open name filename str wb for name bt name expr call attribute write name outfile name bt \n",
      "Original summary: convenience for emitting the bytes we generate to file \n",
      "Predicted summary:  stringify stringify reduces statsd unstable rhel rhel instances jacobian rhel response subdirectories scrolled vserver execution dkl mises metric excel tessellates vincent cmyk unavailable successive strategy strategy invalidates invalidates invalidates leave blanks affiliations pythonpath disk eqns folders fixture rotate pda\n",
      "\n",
      "\n",
      "Review: module functiondef arguments name param assign name list for name call attribute values name augassign name add name return name \n",
      "Original summary: get all the element in list table \n",
      "Predicted summary:  stringify stringify reduces statsd unstable rhel rhel instances jacobian rhel response subdirectories scrolled vserver execution dkl mises metric excel tessellates vincent cmyk unavailable successive strategy successive strategy invalidates invalidates invalidates leave blanks affiliations pythonpath disk eqns fixture rotate invalidates\n",
      "\n",
      "\n",
      "Review: module functiondef short token arguments assign name hash call attribute sha1 name hashlib call attribute uuid name expr call attribute update name hash attribute secret key name settings return subscript call attribute hexdigest name hash slice num \n",
      "Original summary: generate hash that can be used as an application identifier \n",
      "Predicted summary:  stringify stringify reduces statsd unstable rhel rhel instances jacobian rhel response subdirectories scrolled vserver execution dkl mises metric successive unescape allows tkinter generic invalidates inversed objects extracted invalidates unhelpful unhelpful capped rhel fairly fairly preconditioned billingpos billingpos lomb scheme\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "  print(\"Review:\",seq2text(x_val[i]))\n",
    "  print(\"Original summary:\",seq2summary(y_val[i]))\n",
    "  print(\"Predicted summary:\",decode_sequence(x_val[i].reshape(1,max_len_text)))\n",
    "  print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
