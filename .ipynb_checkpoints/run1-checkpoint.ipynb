{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In[1]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from attention import AttentionLayer\n",
    "from contraction_mapping import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "rom sklearn.externals import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np  \n",
    "import pandas as pd \n",
    "import re           \n",
    "from bs4 import BeautifulSoup \n",
    "from keras.preprocessing.text import Tokenizer \n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from nltk.corpus import stopwords   \n",
    "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Concatenate, TimeDistributed, Bidirectional\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import warnings\n",
    "pd.set_option(\"display.max_colwidth\", 200)\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In[2]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('training_dataset/train.ast.src', 'r')\n",
    "code_data = []\n",
    "for i in range(20):\n",
    "    input_data = str(f.readline())\n",
    "    code_data.append(input_data)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "stop_words.remove('if')\n",
    "stop_words.remove('for')\n",
    "stop_words.remove('this')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('training_dataset/train.txt.tgt', 'r')\n",
    "summary_data = []\n",
    "for i in range(20):\n",
    "    input_data = str(f.readline())\n",
    "    summary_data.append(input_data)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In[3]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summary_cleaner(text):\n",
    "    newString = re.sub('\"','', text)\n",
    "    newString = ' '.join([contraction_mapping[t] if t in contraction_mapping else t for t in newString.split(\" \")])    \n",
    "    newString = re.sub(r\"'s\\b\",\"\",newString)\n",
    "    newString = re.sub(\"[^a-zA-Z]\", \" \", newString)\n",
    "    newString = newString.lower()\n",
    "    tokens=newString.split()\n",
    "    newString=''\n",
    "    for i in tokens:\n",
    "        if len(i)>1:                                 \n",
    "            newString=newString+i+' '  \n",
    "    return newString"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In[4]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_summary = []\n",
    "for t in summary_data:\n",
    "    cleaned_summary.append(summary_cleaner(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(cleaned_summary)):\n",
    "    cleaned_summary[i] = '_START_ '+ cleaned_summary[i] + ' _END_'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print(cleaned_summary[23])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In[5]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "text_word_count = []\n",
    "summary_word_count = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print(len(code_data[1000]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in code_data:\n",
    "    text_word_count.append(len(i.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in cleaned_summary:\n",
    "    summary_word_count.append(len(i.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "length_df = pd.DataFrame({'text':text_word_count, 'summary':summary_word_count})\n",
    "length_df.to_csv('length_data.csv')\n",
    "length_df.hist(bins = 30)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In[6]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len_text = 300\n",
    "max_len_summary = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_tr,x_val,y_tr,y_val=train_test_split(code_data, cleaned_summary, test_size=0.1, random_state=0, shuffle=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In[7]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_tokenizer = Tokenizer()\n",
    "x_tokenizer.fit_on_texts(list(x_tr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "onvert text sequences into integer sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_tr    =   x_tokenizer.texts_to_sequences(x_tr) \n",
    "x_val   =   x_tokenizer.texts_to_sequences(x_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "adding zero upto maximum length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_tr    =   pad_sequences(x_tr,  maxlen=max_len_text, padding='post') \n",
    "x_val   =   pad_sequences(x_val, maxlen=max_len_text, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_voc_size   =  len(x_tokenizer.word_index) +1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_tokenizer = Tokenizer()\n",
    "y_tokenizer.fit_on_texts(list(y_tr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "onvert summary sequences into integer sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_tr    =   y_tokenizer.texts_to_sequences(y_tr) \n",
    "y_val   =   y_tokenizer.texts_to_sequences(y_val) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "adding zero upto maximum length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_tr    =   pad_sequences(y_tr, maxlen=max_len_summary, padding='post')\n",
    "y_val   =   pad_sequences(y_val, maxlen=max_len_summary, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_voc_size  =   len(y_tokenizer.word_index) +1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In[8]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K \n",
    "K.clear_session() \n",
    "latent_dim = 30 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In[9]:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encoder attempt with 3 LSTM layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_inputs = Input(shape=(max_len_text,)) \n",
    "enc_emb = Embedding(x_voc_size, latent_dim,trainable=True)(encoder_inputs) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "STM 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_lstm1 = LSTM(latent_dim,return_sequences=True,return_state=True) \n",
    "encoder_output1, state_h1, state_c1 = encoder_lstm1(enc_emb) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "STM 2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_lstm2 = LSTM(latent_dim,return_sequences=True,return_state=True) \n",
    "encoder_output2, state_h2, state_c2 = encoder_lstm2(encoder_output1) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "STM 3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_lstm3=LSTM(latent_dim, return_state=True, return_sequences=True) \n",
    "encoder_outputs, state_h, state_c= encoder_lstm3(encoder_output2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In[10]:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ecoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_inputs = Input(shape=(None,)) \n",
    "dec_emb_layer = Embedding(y_voc_size, latent_dim,trainable=True) \n",
    "dec_emb = dec_emb_layer(decoder_inputs) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "STM using encoder_states as initial state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True) \n",
    "decoder_outputs,decoder_fwd_state, decoder_back_state = decoder_lstm(dec_emb,initial_state=[state_h, state_c]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ttention Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "attn_layer = AttentionLayer(name='attention_layer') \n",
    "attn_out, attn_states = attn_layer([encoder_outputs, decoder_outputs]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concat attention output and decoder LSTM output "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_concat_input = Concatenate(axis=-1, name='concat_layer')([decoder_outputs, attn_out])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ense layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_dense = TimeDistributed(Dense(y_voc_size, activation='softmax')) \n",
    "decoder_outputs = decoder_dense(decoder_concat_input) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 300)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 300, 30)      12510       input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     [(None, 300, 30), (N 7320        embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   [(None, 300, 30), (N 7320        lstm[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, None, 30)     2910        input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   [(None, 300, 30), (N 7320        lstm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lstm_3 (LSTM)                   [(None, None, 30), ( 7320        embedding_1[0][0]                \n",
      "                                                                 lstm_2[0][1]                     \n",
      "                                                                 lstm_2[0][2]                     \n",
      "__________________________________________________________________________________________________\n",
      "attention_layer (AttentionLayer ((None, None, 30), ( 1830        lstm_2[0][0]                     \n",
      "                                                                 lstm_3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concat_layer (Concatenate)      (None, None, 60)     0           lstm_3[0][0]                     \n",
      "                                                                 attention_layer[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed (TimeDistribut (None, None, 97)     5917        concat_layer[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 52,447\n",
      "Trainable params: 52,447\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs) \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In[11]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In[12]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In[ ]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    }
   ],
   "source": [
    "history=model.fit([x_tr,y_tr[:,:-1]], y_tr.reshape(y_tr.shape[0],y_tr.shape[1], 1)[:,1:] ,epochs=10,callbacks=[es],batch_size=512, validation_data=([x_val,y_val[:,:-1]], y_val.reshape(y_val.shape[0],y_val.shape[1], 1)[:,1:]))\n",
    "reverse_target_word_index=y_tokenizer.index_word \n",
    "reverse_source_word_index=x_tokenizer.index_word \n",
    "target_word_index=y_tokenizer.word_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print(len(reverse_target_word_index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In[ ]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Completed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "i = 'model_test.sav'<br>\n",
    "ickle.dump(model, open(fi, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('test_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "onvert the index to word for target and source vocabulary<br>\n",
    "reverse_target_word_index=y_tokenizer.index_word <br>\n",
    "reverse_source_word_index=x_tokenizer.index_word <br>\n",
    "target_word_index=y_tokenizer.word_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In[ ]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_model = Model(inputs=encoder_inputs,outputs=[encoder_outputs, state_h, state_c])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "decoder inference<br>\n",
    "Below tensors will hold the states of the previous time step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_state_input_h = Input(shape=(latent_dim,))\n",
    "decoder_state_input_c = Input(shape=(latent_dim,))\n",
    "decoder_hidden_state_input = Input(shape=(max_len_text,latent_dim))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the embeddings of the decoder sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dec_emb2= dec_emb_layer(decoder_inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To predict the next word in the sequence, set the initial states to the states from the previous time step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=[decoder_state_input_h, decoder_state_input_c])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ttention inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attn_out_inf, attn_states_inf = attn_layer([decoder_hidden_state_input, decoder_outputs2])\n",
    "decoder_inf_concat = Concatenate(axis=-1, name='concat')([decoder_outputs2, attn_out_inf])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A dense softmax layer to generate prob dist. over the target vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_outputs2 = decoder_dense(decoder_inf_concat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Final decoder model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_model = Model(\n",
    "[decoder_inputs] + [decoder_hidden_state_input,decoder_state_input_h, decoder_state_input_c],\n",
    "[decoder_outputs2] + [state_h2, state_c2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "n[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq):\n",
    "    # Encode the input as state vectors.\n",
    "    e_out, e_h, e_c = encoder_model.predict(input_seq)\n",
    "\n",
    "    # Generate empty target sequence of length 1.\n",
    "    target_seq = np.zeros((1,1))\n",
    "\n",
    "    # Chose the 'start' word as the first word of the target sequence\n",
    "    target_seq[0, 0] = target_word_index['start']\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    while not stop_condition:\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + [e_out, e_h, e_c])\n",
    "\n",
    "        # Sample a token\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_token = reverse_target_word_index[sampled_token_index]\n",
    "        if(sampled_token!='end'):\n",
    "            decoded_sentence += ' '+sampled_token\n",
    "\n",
    "            # Exit condition: either hit max length or find stop word.\n",
    "            if (sampled_token == 'end' or len(decoded_sentence.split()) >= (max_len_summary-1)):\n",
    "                stop_condition = True\n",
    "\n",
    "        # Update the target sequence (of length 1).\n",
    "        target_seq = np.zeros((1,1))\n",
    "        target_seq[0, 0] = sampled_token_index\n",
    "\n",
    "        # Update internal states\n",
    "        e_h, e_c = h, c\n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "n[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seq2summary(input_seq):\n",
    "    newString=''\n",
    "    for i in input_seq:\n",
    "      if((i!=0 and i!=target_word_index['start']) and i!=target_word_index['end']):\n",
    "        newString=newString+reverse_target_word_index[i]+' '\n",
    "    return newString"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seq2text(input_seq):\n",
    "    newString=''\n",
    "    for i in input_seq:\n",
    "      if(i!=0):\n",
    "        newString=newString+reverse_source_word_index[i]+' '\n",
    "    return newString"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "n[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fo = open('output.txt', 'w')\n",
    "for i in range(10):\n",
    "  fo.write(\"Code:\" + str(seq2text(x_val[i])) + \"\\n\")\n",
    "  fo.write(\"Original summary:\" + str(seq2summary(y_val[i])) + \"\\n\")\n",
    "  fo.write(\"Predicted summary:\"+ str(decode_sequence(x_val[i].reshape(1,max_len_text))) + \"\\n\")\n",
    "  fo.write(\"\\n\\n\")\n",
    "fo.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
